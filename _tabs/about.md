---
# the default layout is 'page'
icon: fas fa-info-circle
order: 4
---

<!-- > Add Markdown syntax content to file `_tabs/about.md`{: .filepath } and it will show up on this page.
{: .prompt-tip } -->

# Table of Contents
{:.no_toc}
0. this unordered seed list will be replaced by toc as unordered list
{:toc}

---

# 최근 활동
(2023.12 ~ ) DebConf24 Organizer<br>
(2023.11 ~ ) 네이버 부스트캠프 AI Tech 6기<br>
(2023.10 ~) 네이버 코칭스터디 13기 리드부스터 수료<br>

---

# 경력사항
(2022.11 ~ 2023.06) 바이브컴퍼니 신기술개발팀 매니저<br>
(2021.02 ~ 2022.02) 부경대학교 인공지능융합학과 박사과정 중퇴<br>
(2018.03 ~ 2021.02) 부경대학교 인공지능융합학과 석사 졸업<br>
(2014.03 ~ 2018.02) 부경대학교 IT융합응용공학과 학사 졸업<br>

# 논문 및 프로젝트

## 논문

**3차원 골격정보 기반 관절 간 상관관계를 이용한 행동인식**

- 본 논문에서는 관절간의 상관관계를 이용한 사람 행동인식 방법을 제안한다.
- 3차원 관절 데이터는 Kinectv2 센서를 사용한 NTU-RGB60을 활용한다.
- 각 관절을 정규화된 좌표로 표현하고, 각 관절들 사이의 시간 및 공간적 상관관계는 각각 한 프레임 내에서와 연속된 두 프레임 사이에서 코사인 유사도로 정의한다.
- 계산된 상관관계 정보를 토대로 LSTM(Long-Short Term Memory)을 이용하여 행동을 추정한다.
- 제안 방법은 3차원 골격데이터 기반 행동인식 문제에서 각 관절들의 연관성 정보가 성능 향상에 효과가 있음을 보여준다.

**GCN-LSTM과 슬라이딩 윈도우를 이용한 골격 기반 사람 행동 인식 비교**

- 본 논문에서 그래프 합성곱(Graph Convolutional)과 LSTM(Long Short Term Memory)를 이용한 골격 기반 행동 인식 방법을 제안하고, 한 영상을 주어진 슬라이딩 창 크기에 따라 나누어 인식하여 비교한다.
- 골격 기반 행동 인식은 영상 데이터를 다루므로 데이터의 시계열성 학습을 위해 LSTM을 사용하고, LSTM이 입력으로 1차원 데이터만을 다루기 때문에 각 프레임에서 2차원 또는 3차원으로 표현되는 골격 모양을 표현할 수 있게 그래프 합성곱을 함께 사용하는 네트워크를 사용하여 그래프 정보를 포함하는 것이 골격 기반 행동 인식 성능 향상에 효과가 있음으로 보인다.
- 더불어 NTU-RGB+D 데이터셋에서 효율적인 학습을 위해 LSTM이 각 시간 단위별로 그래프 합성곱 특징을 어떻게 학습하는 가를 비교해 본다.

**GCN-LSTM 과 HMM을 이용한 골격 기반 사람 행동 비디오 요약**

- 본 논문에서는 주어진 행동의 시공간 특징을 분석하고 주요 자세별로 요약하는 모델을 제안한다.
- 먼저 시공간 특징은 그래프 합성곱 네트워크(Graph Convolutional Network, GCN)과 LSTM(Long Short Term Memory) 결합한 인코더에서 추출한다.
- 그리고 행동 비디오를 각 프레임별 상태를 추적하고 요약하기 위해 HMM(Hidden Markov Model)을 사용한다.
- 제안 모델은 GCN-LSTM 의 결합으로 골격 기반 사람 행동 영상에서 골격 자체 모양 정보와 연속된 프레임간 시간 정보를 순차적으로 얻을 수 있다.
- 또한, 얻어진 시공간 정보들을 HMM 을 통해 프레임별로 정보의 상태를 분석하여 현재 어떤 주요 자세에 해당되는 가를 알 수 있다.

**그래프네트워크 LSTM과 HMM을 이용한 사람 행동 영상 분석**

- 연속된 자세 변화를 나타내는 행동을 각 자세별로 분석하는 연구이다.
- 영상 내 프레임 별로 시간 및 공간 특징을 추출하여 행동을 분류한다.
- 추출한 특징으로 한 행동을 이루는 자세들을 분석하고 자세 흐름을 파악하여 한 행동을 이루는 자세들을 분석하는 시스템을 개발한다.
- 대용량 데이터셋인 NTU-RGB+60을 이용하여 제안된 시스템을 구현하고, 행동 분류와 자세 분석을 시각화한다.


## 프로젝트

**2022.11~2023.06 대검찰청 빅데이터 기반 지능형 증거 통합 분석 플랫폼**

- 사건관리 및 증거분석 플랫폼 운영 대시보드 개발
- 운영 관리 데이터 시각화 기획 및 구현
- 협력기관 데이터 ETL 관리

**2020.08-2020.12 AI 안경디자이너**

- 다양한 안경 모양 분석 및 CNN과 RNN을 이용한 새로운 안경 디자인 모델 개발
- 영상처리를 통해 안경 사진 및 안경 도면에서 테두리 추출
- 추출된 테두리를 RNN을 변형한 모델로 새로운 안경 모양을 디자인하는 시스템 개발
- QtPy와 MariaDB를 이용한 실행파일 형태로 시스템 구현

**2020.01 - 2020.12 미래수산식품 연구센터**

- 질병관리본부에서 제공하는 국민건강데이터를 이용한 통계 기반 분석 시스템 구축
- 식품 추천 시스템 사용자 건강 상태에 맞춘 필요 식품 영양분 분석
- 협업 필터링과 K-means 클러스터링을 이용한 식품 추천

**2020.01-2020.12 첨단 해양산업 오픈랩 구축 및 실감형 융합 콘텐츠 개발**

- 스마트폰의 자이로센서 및 가속도 센서를 이용한 사람 행동 추적 연구
- 행동별 주요 자세 구별을 위해 분류된 연속 은닉 마르코프(CHMM) 모델 개발
- 비터비(Veterbi) 알고리즘을 이용한 최적 은닉 상태 시퀀스를 분석하여 여러 자세를 구별


---

# 수상경력

| 수상처 | 수상내용 | 기간 | 상세설명 |
| --- | --- | --- | --- |
| 부경대학교 IT융합응용공학과와 삼성SST 및 스마트해양수산융합미래인력양성사업단 개최 교내소프트웨어경진대회 | 최우수상 | 2016.11 | 작품명 : 청각장애인을 위한 스마트워치 |
| 부경대학교 IT융합응용공학과와 삼성SST 및 스마트해양수산융합미래인력양성사업단 개최 교내소프트웨어경진대회 | 대상 | 2017.05 | 작품명 : JAVIS(AR을 이용한 사물 및 사람 얼굴과 감정 인식) |