---
title: "Spatial Temporal Graph Convoutional Networks (ST-GCN)" ## 포스트 제목
category:       
    - Paper Review
tags:           
    - deep learning
    - GCN
comments:  true ## 댓글 기능
last_modified_at : 2020-04-13
---

## 1. 논문 소개 및 주제

- 제목 : Spatial Temporal Graph Convolutional Networks for Skeleton-Based Action Recognition
- 저자 : Sijie Yan, Yuanjun Xiong, Dahua Lin
- 학회 : Thirty-second AAAI conference on artificial intelligence
- 발표 년도 : 2018

- 사람 골격데이터를 기반으로한 행동인식 연구
- Graph Convolutional Networks(GCN) 의 변형으로 시공간 그래프를 학습시키는 ST-GCN 소개
- Kinetics, NTU-RGB+D 데이터셋으로 실험

## 2. 연구 동기

- 기존 hand-craft parts or traversal rules based 연구들에서 나타나는 아래 문제점 해결을 위해

1) 골격 표현의 종속성 : 데이터베이스에서 제공하는 관절 개수, 표현 방식에 종속됨

2) 데이터베이스 특화된 실험결과로 인한 일반화의 어려움

## 3. 주요 공헌점

1) ST-GCN 설계 : 골격 데이터 기반 행동인식 연구에 최초로 GCN 응용
- 입력으로 주어지는 관절을 자동적으로 시공간적 관계 연결하므로 기존 연구들과 같이 골격을 손수 만들어 입력으로 주어질 필요가 없어 행동을 표현하는 모델을 만들기가 쉬워진다.

![2020-04-13-STGCN_fig1](/assets/images/2020-04-13-STGCN_fig1.PNG)

- 관절마다 학습가능한 시공간 연결선(엣지)를 가진다.
    * spatial edge : 한 프레임 상 관절들의 관계를 표현
    * temporal edge : 연속된 프레임들 상에서 한 관절에 대한 시간축 연결을 표현 

2) 골격 데이터에 맞게 디자인된 ST-GCN convolution kernel 설계

3) 대용량 데이터셋인 NTU-RGB+D / Kinetics 데이터셋에서 기존 연구보다 적은 노력으로 우수한 성과를 얻음  

## 4. 제안 모델

1) 입출력
- 입력 : 관절 좌표 벡터가 각각 그래프의 노드에 입력
- 출력 : 특징벡터로 추상화된 골격데이터를 softmax를 거쳐 행동 카테고리로 분류

2) Skeleton Graph Construction
- 비방향성 그래프 : $G = (V, E)$
- 노드 집합 : $V = {V_{ti} | 1 <= t <= T, 1 <= i <= N}$
- 각 노드에 입력된 특징 벡터 : $F(v_{ti})$ 