---
title:          "[네이버 부스트캠프 AI Tech 6기] 3주차 회고"
categories:       
    - Naver_BoostCamp_AI
tags:           
    - 회고
    - 부캠
comments: true
last_modified_at : 2023-11-24 20:48:10
toc: true
---

## 피어세션 정리 
- 2주차 피어세션에서는 알고리즘 4문제 / 프로젝트 회의 / 각자 과제 질문을 진행하였다.
    - 광물 캐기
    - 당구 연습
    - 리코챗로봇
    - 혼자서 하는 틱택토
- 이번주는 피어세션 뿐만 아니라 데일리 스크럼 시간에도 각자 프로젝트 주제에 대해서 토론을 해보았다. 결과적으로, 팀원들과 같이 캐글이나 데이콘 끝난 대회를 하나 같이 도전해보기로 했다.
- 더불어 과제 질문으로 gather과 정규표현식, xavier에 관한 질문이 가장 기억에 남는데 3가지 질문에 답을 찾으려고 노력하고 답해보았다.
- 프로젝트 주제를 찾고 구체화 해나가면서 생각보다 아직 두루뭉술한 것 같은 것 같아서 이런 토론 시간을 가지길 잘했다는 생각이 든다. 
- 그리고 프로젝트를 주제를 다듬어 가며 다른 프로젝트 주제들이나 이전에는 어떻게 했는지 찾아보면서 내가 어떤 방향으로 프로젝트를 진행하는게 좋은지, 정리는 어떻게 해야하는지, 어떤 툴이나 라이브러리, 프레임워크를 써야하는지 배워갔다.
- 아쉽게도 이번에 과제가 너무 길어서 이걸 하나하나 파악하고 정리하다보니 질문을 찾을 겨를도 부족했고, 특히 초반에 막히는 부분에서 혼자 해결해보고자 시간을 쏟은 바람에 어려워 진 것 같다ㅠㅠ...

---

## 스폐셜 피어세션
- 이번주부터 금요일에 스폐셜 피어세션을 진행했다.
- 다른 팀의 팀원들을 만나보며 다양한 관심사와 다양한 주제에 대한 고민을 들을 수 있어서 즐거운 시간이었던 것 같다.
- 생각보다 내가 말을 많이 한 것 같아 다음번에는 조금 더 들을 수 있도록 해보고 싶다. 다른 팀원들에 대해 더 알아가고 싶은데 1시간이라는 시간이 너무 짧게만 느껴진다.

---

## 회고

### 잘했던 것, 좋았던 것, 계속할 것
- 시간을 쪼개서 mediums 추천글을 읽고 주피터의 코파일럿 같은 AI 기능을 발견했다! 그래서 생생정보팁에 공유하여 이번주 목표도 달성했다!
- 변성윤 마스터님의 강의를 듣고 "함께자라기 : 애자일로 가는 길" 이라는 책을 구입했다. 읽어보고 리뷰도 남기고 팀을 위하는 자세를 고민하고 행동으로 옮겨야겠다.
- 질의응답 게시판의 이번주차 모든 질문들을 읽어보고 생각지도 못했거나 유용한 질문을 스크랩했다. 학습한 내용을 정리하며 블로깅을 할때 유용할것 같으니 계속 읽어보자!
- 질의응답 게시판에서 아는 것들을 최대한 답변해보았다. 그때그때 못 보기도 하고 설명이 부족한 것도 있는 것 같으니 답변을 잘 정리해보는 연습이 필요할 것 같다. 
- 들어오는 정보를 다 처리하지 못해서 흘려보내는 것들이 아까웠는데 옵시디언을 켜놓고 바로바로 쌓아놓고 있다. 그러니 그 내용을 기억하려고 당시에 애쓰지 않아도 되고 삼천포로 빠지는 일이 적어져 시간을 효율적으로 쓸 수 있는 듯하다.

### 잘못했던 것, 아쉬운 것, 부족한 것 -> 개선방향
- 저번주에 이어 아직 블로그에 2일 1포스팅을 하지 못했다... -> 아무래도 변성윤 마스터님이 알려주신 시간관리법을 적용하여 블로깅 시간을 할당해놓고 꾸준히 할 수 있도록 스스로 동기부여가 필요할 것 같다.
- 과제가 너무 길어서 그때그때 정리하면서 풀었는데 생각보다 시간이 배로 걸렸다. 심지어 시간을 측정해놓고 풀었는데 다른 팀원들보다 딱 2배로 걸려 개선이 시급하다. -> 과제를 통째로 따로 노트정리를 했는데 이부분을 굳이 하지 않고 몰랐던 거나 더 알고싶은 부분, 혹은 유용하다고 생각하는 부분으로 나누어 노트정리를 해야할 것 같다.

### 도전할 것, 시도할 것
- 적어도 2일 1포스팅!!! 정리하지 않는 자 혼란을 맞이할 것이다!!!!
- 변성윤 마스터님의 시간관리법과 추천해주신 책, 그리고 글쓰기 노하우를 적용하여 더 알찬 3주차를 맞이하자!!!

### 공부한 것, 알게된 것, 느낀점 + 추가로 알아본 것
- pytorch gather에 대해 진짜 많이 연구했다.
- encoder 와 decoder에 대해 복습했다.
- xavier 논문을 다시 읽어보기 시작했다.
- ROCm : AMD GPU <-> NVIDIA GPU
- moduleList vs Sequential vs python list
- [python docstring 적는법](https://www.datacamp.com/tutorial/docstrings-python)
- [pytorch hook](https://medium.com/the-dl/how-to-use-pytorch-hooks-5041d777f904)
- [알고리즘 트리 종류](https://towardsdatascience.com/4-types-of-tree-traversal-algorithms-d56328450846)
- [Jupyter AI](https://blog.jupyter.org/generative-ai-in-jupyter-3f7174824862)
- [pytorch module __call__ vs forward()](https://stephencowchau.medium.com/pytorch-module-call-vs-forward-c4df3ff304b1)
- [pytorch buffer 사용이유](https://www.ai-bio.info/pytorch-register-buffer)
- [mm / matmul / mul 차이](https://stackoverflow.com/questions/73924697/whats-the-difference-between-torch-mm-torch-matmul-and-torch-mul)
- BOHB -> 베이지안 하이퍼 파라미터 튜닝
- Ray -> ASHA 스케줄러나 베이지안 알고리즘을 선택해줄 수 있음
- [Sampling Samplers](https://towardsdatascience.com/pytorch-basics-sampling-samplers-2a0f29f0bf2a)