---
title: "2020.02.05 : 1일 1일지" ## 포스트 제목
tag:
    - thinking
    - daily
last_modified_at : 2020-02-05 16:30:00
---

[Main Research Project Page]({% link _posts/2020-02-05-Main_Research.md %})

### 오늘의 고찰

석사 논문 주제 브리핑 요청이 들어와 진지하게 어떤 논문이 될 것인지 구체화 해보려 했다. 너무 높은 곳에서 시작하여 생각하다보니 난잡한 결론에 도달하였기에 정리하고자 글을 남긴다.

## 주제 선정 과정 및 잡설?

주제를 선정하기 위해 가장 처음 한 생각은 내가 로봇을 만든다면 어떤 부위를 만들고 싶을까? 라는 질문이었다. 출발이 좀 이상하지만(?) 인공지능 == 로봇 이라 생각한 꿈에 부푼 발상에서 시작되었다. 그리고 사람의 5가지 감각중 내가 가장 하루 동안 많이 사용한다 생각되며 가장 좋아하는 감각인 "시각, vision"을 선택하게 되었다.

시각은 실시간으로 아주 방대한 양의 정보를 한 번에 받을 수 있는 감각이다. 그렇기 때문일까 컴퓨터 비전(computer vision, CV)이라는 분야는 대량의 데이터를 다루고 있고, 그 데이터들 중 모든 정보가 중요한 것은 아니기 때문에 특징 추출이 특히 도드라지게 중요한 분야가 아닐까 싶다. 물론 기계학습에서는 특징 추출 단계가 모든 도메인에 걸쳐 중요하지만 컴퓨터 비전에서는 데이터 크기가 남다르기 때문에 특히 중요하다고 생각한다.

심층 신경망 시대가 도래하기 전에는 특징 추출을 위해 많은 hand-craft 영상 처리 기법들이 많이 사용되었다. 예를 들어 HOG(Histogram of Gradient), SIFT(Scale Invariant Feature Transform) Optical Flow 등이 있고 이들 중 몇몇은 여전히 많이 쓰이고도 있기도 하다. 하지만, 합성 곱 신경망(Convolutional Neural Networks, CNN)이 등장하면서 사람에 의해 정의된 특징이 아닌 기계 스스로가 찾은 특징은 영상 처리나 인식 분야에 있어 놀라운 성능을 보여주고 있다. 또한, end-to-end 모델이라는 장점 덕분에 어렵기만 했던 영상 처리 분야의 진입장벽을 확 낮춰준 1등 공신이 아닐까 싶다. 또한, 나 역시도 직관적으로 사람이 생각하는 중요하다 느끼는 특징과 기계 입장에서 중요하다 느끼는 특징은 다를거라 생각하여 이 방법이 나쁘다고 생각하지 않는다. 오히려 좋다고 생각하는 편이다.

그래서 처음에는 이런 합성곱 신경망의 약점을 꼬집어 새로운 모델을 개발하고 싶었다. 내가 생각하는 합성 곱 신경망의 가장 큰 단점은 합성곱(convolution) 연산에 의해 영상에서 공간적 특성은 잘 학습할 수 있으나, 시간적 특성, long-range dependency등은 배우기 어렵고 무엇보다 그 의미를 이해할 수 없다는 것이라고 생각한다. 다시 말해 시간에 따른 변화를 이해하기 어렵다고 생각한다. 물론 이는 이미 숱한 연구자들이 생각한 문제이다. 그래서 long-range dependency를 더 잘 찾을 수 있도록 LSTM+CNN부터 시작하여 Non-local, TSN(Temporal Segment Network)나 Timeception 등 여러 방법들이 합성곱 연산을 이용하여 해결할 수 있는 방안을 연구해왔다. 하지만, 늘 그렇듯 end-to-end 모델인 심층신경망으로는 사람이 이해할 수 있는 의미를 가지는 시간 단위 segment를 찾고 설명할 방법이 부족했다.

이쯤 정리하자면 video understanding 분야에 있어 내가 관심있게 보는 부분은 사람이 이해 할 수 있는 의미를 파악하는 것이다. 영상에서는 물론 공간적인 정보도 중요하지만 이는 ImageNet challenge등에서 이미 기계가 사람을 뛰어넘는 성능을 많이 보여주므로 더이상 성능향상을 위해 논하기에는 현재 내가 가진 연구역량과 시간, 자원에 제약을 많이 받을 수 있는 연구라 판단되었다. 그리하여 꾸준히 관심을 두었던 시계열 자료 분석의 시각으로 이 분야를 바라보게 되었고 이러한 결론에 도달하였다. 이를 응용한다면 video captioning이나 video Q&A등 여러 곳에 사용될 수 있을 것이라 생각된다.

여기서 가장 큰 문제가 발생한다. 과연 나는 어떤 문제로, 어떻게 나의 전문성을 어필할 수 있을까? 영상을 분석함에 있어 공간적 특성을 아예 배제할 수 없는 것은 자명하므로 나는 이 과정을 상대적으로 적게 투자할 수 있는 문제를 골라야 할 것이다. 그리고 시계열 분석이 의미가 있는 일이 필요하다. 그리고 그 과정에서 배운 기초 이론들로 모델을 개선하거나 개발하는 것에 더 큰 관심이 있기 때문에 데이터셋을 직접 만들어야할 가능성이 크다. 따라서 문제의 범위는 너무 넓지 않아야한다. 이 모든 조건에 부합하는 문제는 보통 어려운 일이 아니었다.

현재는 노인이나 아이들이 혼자 있을 때 무료함을 달래주거나 케어를 할 수 있도록 하는 로봇을 개발한다는 관점에서 문제를 찾아보려 애쓰고 있다. 예를 들어 사람이 보여주는 제스처나 행동을 인식하여 그에 맞는 반응을 하는 로봇이라 던가 동작만으로 할 수 있는 게임(침묵의 007), 몸으로 말해요 같은 동작 인식 게임을 할 수 있는 로봇을 개발! 한다는 방향으로 시나리오를 만들고 데이터셋을 훑어보고 있는 중이다.

어떤 글에서 지나가다 본 적이 있는데 특히 한국 학생들은 문제를 찾을 줄 모른다고 했던 기억이 있다. 적어도 나에게는 맞는 말인 것 같았다. 평소에는 주어진 문제만 풀면 되니까 그저 알고 있는 방법을 총동원하여 상상하는 일 밖에 없었지만 막상 그 문제 자체를 만들려고 하니 아무런 기초가 없는 것이나 다름 없는 상태가 되었다. 많은 다른 회사나 연구소, 대학 연구실에서는 문제가 보통 펀드에 따라 주어진다. 그럼 그 주제가 본인이 좋아하건 안 좋아하건 할 수 밖에 없는 상황에 놓이게 되고 도비가 되어버린다...... 창작의 고통을 겪고 있는 요즘 차라리 그런 도비가 되고 싶다는 생각을 많이 할때가 있다. 그리고 문제를 만들고 헛점을 발견하고 다시 만들고를 발견하는 것을 반복하면서 실력도 많이 부족하게 느껴지고 게으름 때문에 경험 부족이라는 생각에 잠겨 자신을 채찍질할 때가 많이 있다. 하지만, 그럼에도 불구하고 이 자리에 있는 이유는 나는 감당할 수 없어 보이는 일도 결국 할 수 있는 사람이라는 믿음이 아직 남아있고, 다른 할 수 있는 일은 많지만 수학과 컴퓨터에는 지독할 정도로 애증이 남아있기 때문에 떠날 수 없다. 적어도 나 스스로는 극복할 수 있는 사람이라 믿는다. (tmi가 길어졌다......)

## 핵심 키워드

- video understanding
- 케어봇
- 노인, 아이들
- 동작 인식 게임
- CNN


## 오늘 찾은 데이터셋 및 참고 논문

### 데이터셋

- [HON4D: Histogram of Oriented 4D Normals for Activity Recognition from Depth Sequences](http://www.cs.ucf.edu/~oreifej/HON4D.html#New%20dataset%20-%20MSR%20Action%20Pairs)

### 논문

- [Design of Music Learning Assistant Based on Music and Score Recognition](http://pknu.dcollection.net/public_resource/pdf/000002229125_20200205122634.pdf)

- [Hand gesture recognition based on dynamic Bayesian network framework](https://reader.elsevier.com/reader/sd/pii/S0031320310001366?token=47B43330A7CA6007B984DB73D96CAAB92C1E3A75375C20258D5F65FC8650AA2F2A3519DE8934795A06A8CEC3E48CA0C6)

위 두 논문은 같은 연구실에서 졸업한 선배님들의 논문이다. 본 연구와 큰 관련은 없지만 연구 방향이나 느낌을 위해 남긴다.